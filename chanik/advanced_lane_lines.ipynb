{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        write_name = 'calibration/'+fname.replace(\"calibration\", \"output_calibration\").replace(\"../camera_cal\\\\\", \"\")\n",
    "        cv2.imwrite(write_name, img)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrate, calculate distortion coefficients, and test undistortion on an image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../camera_cal\\calibration1.jpg failed to find corners\n",
      "../camera_cal\\calibration4.jpg failed to find corners\n",
      "../camera_cal\\calibration5.jpg failed to find corners\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Undistorted Image')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        # Do camera calibration given object points and image points\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "        \n",
    "        # Undistort\n",
    "        dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "        # Write into a file\n",
    "        pure_file_name = fname.replace(\"../camera_cal\\\\\", \"\")\n",
    "        undistorted_file_name = 'undistorted/'+pure_file_name.replace(\"calibration\", \"undistorted_calibration\")\n",
    "        cv2.imwrite(undistorted_file_name, dst)\n",
    "        \n",
    "        # Save the camera calibration result for later use\n",
    "        dist_pickle = {}\n",
    "        dist_pickle[\"mtx\"] = mtx\n",
    "        dist_pickle[\"dist\"] = dist\n",
    "        pickle_file_name = 'pickle/'+pure_file_name.replace(\"calibration\", \"dist_pickle\").replace(\".jpg\", \".p\")\n",
    "        pickle.dump( dist_pickle, open(pickle_file_name, \"wb\" ) )\n",
    "    else:\n",
    "        print(fname+\" failed to find corners\")\n",
    "        \n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use color transforms, gradients, etc., to create a thresholded binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../test_images\\straight_lines1.jpg\n",
      "Processing ../test_images\\straight_lines2.jpg\n",
      "Processing ../test_images\\test1.jpg\n",
      "Processing ../test_images\\test2.jpg\n",
      "Processing ../test_images\\test3.jpg\n",
      "Processing ../test_images\\test4.jpg\n",
      "Processing ../test_images\\test5.jpg\n",
      "Processing ../test_images\\test6.jpg\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Read all the file names in ../test_images folder\n",
    "images = glob.glob('../test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "    print(\"Processing \"+fname)\n",
    "    \n",
    "    # 0) Read current test image file\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    s_channel = hls[:,:,2]\n",
    "\n",
    "    # 3) Explore gradients in other colors spaces / color channels to see what might work better\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "    # Threshold x gradient\n",
    "    thresh_min = 20\n",
    "    thresh_max = 100\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Threshold color channel\n",
    "    s_thresh_min = 170\n",
    "    s_thresh_max = 255\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    "\n",
    "    # Stack each channel to view their individual contributions in green and blue respectively\n",
    "    # This returns a stack of the two binary images, whose components you can see as different colors\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    \n",
    "    output_filename = '../output_images/gradient_'+fname.replace(\"../test_images\\\\\", \"\")\n",
    "    cv2.imwrite(output_filename, combined_binary*255)\n",
    "    #cv2.imshow(\"combined_binary\", combined_binary)\n",
    "    #cv2.waitKey(500)\n",
    "\n",
    "# Plot the result\n",
    "#f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "#f.tight_layout()\n",
    "#ax1.imshow(img)\n",
    "#ax1.set_title('Original Image', fontsize=25)\n",
    "#ax2.imshow(combined_binary, cmap='gray')\n",
    "#ax2.set_title('Thresholded S', fontsize=25)\n",
    "#plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'gradient_straight_lines1')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_img = cv2.imread(\"../output_images/gradient_test6.jpg\")\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "ax1.imshow(gradient_img)\n",
    "ax1.set_title('gradient_straight_lines1', fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../output_images/gradient_test3.jpg\n",
      "warped_filename = ../output_images/warped_test3.jpg\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Read all the file names in ../test_images folder\n",
    "images = glob.glob('../output_images/gradient_test3.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "    print(\"Processing \"+fname)\n",
    "    \n",
    "    # 0) Read current gradient image file\n",
    "    gradient_img = cv2.imread(fname)\n",
    "    \n",
    "    # 1) Grab the image shape\n",
    "    img_size = (gradient_img.shape[1], gradient_img.shape[0])\n",
    "    \n",
    "    # For source points I'm grabbing the outer four detected corners\n",
    "    \n",
    "    # For gradient_straight_lines1.jpg\n",
    "    #src = np.float32([[590,440], [675,440], [1070,700], [240,700]])\n",
    "    #plt.plot(590, 440, \"*\")\n",
    "    #plt.plot(675, 440, \"*\")\n",
    "    #plt.plot(1070,700, \"*\")\n",
    "    #plt.plot(240, 700, \"*\")\n",
    "\n",
    "    plt.imshow(gradient_img)\n",
    "    \n",
    "    # For gradient_test3.jpg\n",
    "    src = np.float32([[630,445], [710,445], [1080,700], [260,700]])\n",
    "    plt.plot(630, 445, \"*\")\n",
    "    plt.plot(710, 445, \"*\")\n",
    "    plt.plot(1080,700, \"*\")\n",
    "    plt.plot(260, 700, \"*\")\n",
    "    \n",
    "    # define 4 destination points dst\n",
    "    offset_top = 10\n",
    "    offset_bottom = 10\n",
    "    offset_left = 400\n",
    "    offset_right = 400\n",
    "    dst = np.float32([[offset_left, offset_top], [img_size[0]-offset_right, offset_top], \n",
    "                                     [img_size[0]-offset_right, img_size[1]-offset_bottom], \n",
    "                                     [offset_left, img_size[1]-offset_bottom]])\n",
    "    \n",
    "    #plt.plot(offset_left             , offset_top,             '*')\n",
    "    #plt.plot(img_size[0]-offset_right, offset_top,             '*')\n",
    "    #plt.plot(img_size[0]-offset_right, img_size[1]-offset_bottom, '*')\n",
    "    #plt.plot(offset_left             , img_size[1]-offset_bottom, '*')\n",
    "    \n",
    "    # d) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "        \n",
    "    # e) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "    warped = cv2.warpPerspective(gradient_img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    #cv2.imshow(\"warped\", warped)\n",
    "    \n",
    "    warped_filename = '../output_images/warped_'+fname.replace(\"../output_images/gradient_\", \"\")\n",
    "    print(\"warped_filename = \"+warped_filename)\n",
    "    cv2.imwrite(warped_filename, warped)\n",
    "    cv2.imshow(\"warped\", warped)\n",
    "    #cv2.waitKey(500)\n",
    "\n",
    "# Plot the result\n",
    "#f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "#f.tight_layout()\n",
    "#ax1.imshow(img)\n",
    "#ax1.set_title('Original Image', fontsize=25)\n",
    "#ax2.imshow(combined_binary, cmap='gray')\n",
    "#ax2.set_title('Thresholded S', fontsize=25)\n",
    "#plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23f058f33a0>,\n",
       " <matplotlib.lines.Line2D at 0x23f058f3490>,\n",
       " <matplotlib.lines.Line2D at 0x23f058f3550>]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load our image\n",
    "# `mpimg.imread` will load .jpg as 0-255, so normalize back to 0-1\n",
    "img = mpimg.imread('../output_images/warped_test3.jpg')/255\n",
    "\n",
    "def hist(img):\n",
    "    # TO-DO: Grab only the bottom half of the image\n",
    "    # Lane lines are likely to be mostly vertical nearest to the car\n",
    "    bottom_half = img[img.shape[0]//2:,:]\n",
    "    \n",
    "    # TO-DO: Sum across image pixels vertically - make sure to set `axis`\n",
    "    # i.e. the highest areas of vertical lines should be larger values\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    \n",
    "    return histogram\n",
    "\n",
    "# Create histogram of image binary activations\n",
    "histogram = hist(img)\n",
    "\n",
    "# Visualize the resulting histogram\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\core\\src\\array.cpp:3229: error: (-215:Assertion failed) cn <= 4 in function 'cv::scalarToRawData'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-5d0029a568f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m \u001b[0mout_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_polynomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_warped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-173-5d0029a568f6>\u001b[0m in \u001b[0;36mfit_polynomial\u001b[1;34m(binary_warped)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfit_polynomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_warped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;31m# Find our lane pixels first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[0mleftx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlefty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrighty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_lane_pixels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_warped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;31m### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-173-5d0029a568f6>\u001b[0m in \u001b[0;36mfind_lane_pixels\u001b[1;34m(binary_warped)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m# Draw the windows on the visualization image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n\u001b[0m\u001b[0;32m     55\u001b[0m         (win_xleft_high,win_y_high),(0,255,0), 2) \n\u001b[0;32m     56\u001b[0m         cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\core\\src\\array.cpp:3229: error: (-215:Assertion failed) cn <= 4 in function 'cv::scalarToRawData'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load our image\n",
    "binary_warped = mpimg.imread('../output_images/warped_test3.jpg')\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    print(left_fit)\n",
    "    print(right_fit)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return out_img\n",
    "\n",
    "\n",
    "out_img = fit_polynomial(binary_warped)\n",
    "\n",
    "plt.imshow(out_img)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
